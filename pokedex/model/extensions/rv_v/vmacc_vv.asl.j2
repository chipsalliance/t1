{#-
  inst vd, vs1, vs2, vm; vm mask is optional

  eew(vd, vs1, vs2) = sew
-#}
{%- macro vmop_vv_body(name, compute) %}
  if !isEnabled_VS() then
    return IllegalInstruction();
  end
  if VTYPE.ill then
    return IllegalInstruction();
  end
  if !IsZero(VSTART) then
    return IllegalInstruction();
  end

  let vd: VRegIdx = UInt(GetRD(instruction));
  let vs2: VRegIdx = UInt(GetRS2(instruction));
  let vs1: VRegIdx = UInt(GetRS1(instruction));
  let vm: bit = GetVM(instruction);

  let vl: integer = VL;
  let sew: integer{8, 16, 32, 64} = VTYPE.sew;
  let vreg_align: integer{1, 2, 4, 8} = getAlign(VTYPE);

  if vm == '0' && vd == 0 then
    // overlap with mask
    return IllegalInstruction();
  end
  if vd MOD vreg_align != 0 then
    // vd is not aligned with lmul group
    return IllegalInstruction();
  end
  if vs2 MOD vreg_align != 0 then
    // vs2 is not aligned with elmul group
    return IllegalInstruction();
  end
  if vs1 MOD vreg_align != 0 then
    // vs2 is not aligned with elmul group
    return IllegalInstruction();
  end

  case sew of
    when 8 => begin
      for idx = 0 to vl - 1 do
        if vm != '0' || V0_MASK[idx] then
          let srcd : bits(8) = VRF_8[vd, idx];
          let src2 : bits(8) = VRF_8[vs2, idx];
          let src1 : bits(8) = VRF_8[vs1, idx];
          let res : bits(8) = {{compute}};
          VRF_8[vd, idx] = res;
        end
      end
    end

    when 16 => begin
      for idx = 0 to vl - 1 do
        if vm != '0' || V0_MASK[idx] then
          let srcd : bits(16) = VRF_16[vd, idx];
          let src2 : bits(16) = VRF_16[vs2, idx];
          let src1 : bits(16) = VRF_16[vs1, idx];
          let res : bits(16) = {{compute}};
          VRF_16[vd, idx] = res;
        end
      end
    end

    when 32 => begin
      for idx = 0 to vl - 1 do
        if vm != '0' || V0_MASK[idx] then
          let srcd : bits(32) = VRF_32[vd, idx];
          let src2 : bits(32) = VRF_32[vs2, idx];
          let src1 : bits(32) = VRF_32[vs1, idx];
          let res : bits(32) = {{compute}};
          VRF_32[vd, idx] = res;
        end
      end
    end

    when 64 => Todo("support sew=64");

    otherwise => Unreachable();
  end

  logWrite_VREG_elmul(vd, vreg_align);

  makeDirty_VS();
  clear_VSTART();
  PC = PC + 4;
  return Retired();
{% endmacro -%}

func Execute_VMACC_VV(instruction: bits(32)) => Result
begin
{{- vmop_vv_body("vmacc_vv", "srcd + src1 * src2") -}}
end

func Execute_VNMSAC_VV(instruction: bits(32)) => Result
begin
{{- vmop_vv_body("vnmsac_vv", "srcd - src1 * src2") -}}
end

func Execute_VMADD_VV(instruction: bits(32)) => Result
begin
{{- vmop_vv_body("vmadd_vv", "src2 + src1 * srcd") -}}
end

func Execute_VNMSUB_VV(instruction: bits(32)) => Result
begin
{{- vmop_vv_body("vnmsub_vv", "src2 - src1 * srcd") -}}
end
